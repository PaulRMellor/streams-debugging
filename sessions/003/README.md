## Schema registry and why it is useful

Let's start by saying that this is an optional component which is useful in event driven architectures where Kafka is
used as an intermediary to distributes data asynchronously among different clients. Why would you want to add this
complexity, why not simply agree on a message schema, put it in shared library and live with that?

When integrating through Kafka, **projects need to collaborate on the same data**, so they all need to know the
metadata (which fields are available and what are their types). Using schemas (message formats), data **storage and
processing is more efficient**, because we don't need to send the schema with each message, and numbers can be stored in
their more efficient binary representation.

A shared repository of all schemas used by your organization is important to make siloed knowledge shared and explicit.
Centralizing the schema management enables **schema versioning** (consumers transparently gets old schemas to decode old
messages) and **data policy enforcement** (schemas can evolve safely without introducing breaking changes).

![](images/serdes.png)

[Red Hat Service Registry](https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-service-registry)
is based on [Apicurio Registry](https://www.apicur.io/registry), which is a schema registry for REST APIs (OpenAPI) and
message schemas (AsyncAPI). It supports pluggable storage (in-memory, Kafka, PostgreSQL), schema versioning, schema
validation and provides a **Maven plugin** to automatically register artifacts at build time and **Java
serializers/deserializers** (SerDes) for Avro, Protobuf and JSON Schema. It also provides a web console and a REST API,
that can be used to query the registry and create/update artifacts. In case of migration from Confluent registry, it is
possible to enable the API translation layer and use a tool called `exportConfluent` to migrate the existing schemas.

A registered schema is uniquely identified by the tuple `(groupId, artifactId, version)`. The `groupId` is provided by
the user and it is just a way to logically group artifacts. By default, the `artifactId` is equal to the topic name plus
`-key` or `-value` suffix, depending on whether the serializer was used for the message key or value. The `globalId`
and `contentId` are generated by the server. The `globalId` is the unique id of an artifact version, while
the `contentId` is the unique id of the artifact content (different artifacts with the same schema have the same id).

The serializer exchanges the `artifactId` for a server generated `globalId`, which is added as record header or inside
the payload, depending on the configuration of the producer application. The deserializer fetches the right schema
version using the `globalId`. If required, you can configure to fetch by `contentId` (Confluent default).
The `CHECK_PERIOD_MS` is the time after which a cached artifact is auto evicted and needs to be fetched again on the
next record.

### Example: schema registry in action

[Deploy the Streams operator and Kafka cluster](/sessions/001). Then, we need to deploy the Service Registry operator
and wait some time for the pods to come up. After that, we can finally deploy the Service Registry instance with
PostgreSQL as storage system.

```sh
$ kubectl create -f sessions/003/sub.yaml
subscription.operators.coreos.com/my-svcreg created
Error from server (AlreadyExists): error when creating "sessions/003/sub.yaml": operatorgroups.operators.coreos.com "local-operators" already exists

$ kubectl get po -n openshift-operators
NAME                                                     READY   STATUS    RESTARTS   AGE
amq-streams-cluster-operator-v2.1.0-8-6dfcc6449d-c2np5   1/1     Running   3          2d20h
apicurio-registry-operator-fb9ffd5cb-89z89               1/1     Running   0          46s

$ kubectl create -f sessions/003/crs
configmap/my-pgsql-init created
persistentvolumeclaim/my-pgsql-pvc created
configmap/my-pgsql-config created
configmap/my-pgsql-env created
statefulset.apps/my-pgsql-ss created
service/my-pgsql-svc created
apicurioregistry.registry.apicur.io/my-registry created

$ kubectl get po
NAME                                              READY   STATUS    RESTARTS   AGE
pod/my-cluster-entity-operator-6b68959588-698hp   3/3     Running   0          165m
pod/my-cluster-kafka-0                            1/1     Running   0          166m
pod/my-cluster-kafka-1                            1/1     Running   0          166m
pod/my-cluster-kafka-2                            1/1     Running   0          166m
pod/my-cluster-zookeeper-0                        1/1     Running   0          168m
pod/my-cluster-zookeeper-1                        1/1     Running   0          168m
pod/my-cluster-zookeeper-2                        1/1     Running   0          168m
pod/my-pgsql-ss-0                                 1/1     Running   0          8m36s
pod/my-registry-deployment-5f5fb7c786-7tj75       1/1     Running   0          53s
```

When all pods are running, we just need to tell our application where it can find the Kafka cluster by setting the
bootstrap URL, and the schema registry by setting the REST endpoint. We also need to provide the truststore location and
password, because we are connecting externally.

```sh
$ export BOOTSTRAP_SERVERS=$(kubectl get k my-cluster -o yaml | yq e '.status.listeners[2].bootstrapServers') \
  && export REGISTRY_URL="http://$(kubectl get apicurioregistries my-registry -o 'jsonpath={.status.info.host}')/apis/registry/v2" \
  && kubectl get secret my-cluster-cluster-ca-cert -o "jsonpath={.data['ca\.p12']}" | base64 -d > /tmp/truststore.p12 \
  && export SSL_TRUSTSTORE_LOCATION="/tmp/truststore.p12" \
  && export SSL_TRUSTSTORE_PASSWORD=$(kubectl get secret my-cluster-cluster-ca-cert -o "jsonpath={.data['ca\.password']}" | base64 -d)

$ pushd sessions/003/kafka-avro && mvn clean compile exec:java -q && popd
~/Documents/streams-debugging/sessions/003/kafka-avro ~/Documents/streams-debugging
Producing records
Records produced
Consuming all records
Record: Hello-1663594981476
Record: Hello-1663594982041
Record: Hello-1663594982041
Record: Hello-1663594982041
Record: Hello-1663594982042
~/Documents/streams-debugging
```

[Look at the code](/sessions/003/kafka-avro) to see how the schema is registered and used. Registration happens at build
time and the Maven plugin execute the following API request for every configured schema artifact. Note that we are using
the default group id, but you can specify a custom one.

```sh
$ export REGISTRY_URL="http://$(kubectl get apicurioregistries my-registry -o 'jsonpath={.status.info.host}')/apis/registry/v2"
$ curl -s -X POST -H "Content-Type: application/json" \
  -H "X-Registry-ArtifactId: my-topic-value" -H "X-Registry-ArtifactType: AVRO" \
    -d @src/main/resources/greeting.avsc $REGISTRY_URL/groups/default/artifacts?ifExists=RETURN_OR_UPDATE
{
  "name": "Greeting",
  "createdBy": "",
  "createdOn": "2022-09-30T06:31:36+0000",
  "modifiedBy": "",
  "modifiedOn": "2022-09-30T06:31:36+0000",
  "id": "my-topic-value",
  "version": "1",
  "type": "AVRO",
  "globalId": 4,
  "state": "ENABLED",
  "contentId": 6
}
```

Finally, let's use the REST API to confirm that our schema was registered correctly. We can also look at the schema
content and metadata, which may be useful for debugging.

```sh
$ curl -s $REGISTRY_URL/search/artifacts | jq
{
  "artifacts": [
    {
      "id": "my-topic-value",
      "name": "Greeting",
      "createdOn": "2022-09-19T13:42:59+0000",
      "createdBy": "",
      "type": "AVRO",
      "state": "ENABLED",
      "modifiedOn": "2022-09-19T13:42:59+0000",
      "modifiedBy": ""
    }
  ],
  "count": 1
}

$ curl -s $REGISTRY_URL/groups/default/artifacts/my-topic-value | jq
{
  "type": "record",
  "name": "Greeting",
  "fields": [
    {
      "name": "Message",
      "type": "string"
    },
    {
      "name": "Time",
      "type": "long"
    }
  ]
}

$ curl -s $REGISTRY_URL/groups/default/artifacts/my-topic-value/meta | jq
{
  "name": "Greeting",
  "createdBy": "",
  "createdOn": "2022-09-19T13:42:59+0000",
  "modifiedBy": "",
  "modifiedOn": "2022-09-19T13:42:59+0000",
  "id": "my-topic-value",
  "version": "1",
  "type": "AVRO",
  "globalId": 1,
  "state": "ENABLED",
  "contentId": 1
}
```
