## Schema registry and why we need it

Let's start by saying that this is an optional component in an event driven architecture where a messaging system like
Kafka is used as an intermediary to distributes data asynchronously among different clients. Why would you want to add
this complexity, why not simply agree on a message schema put it in shared library and live with that?

It turns out that schemas are critical and a shared repository of all schemas used by your organization is important to
make siloed knowledge shared and explicit. Different projects need to collaborate on the same data and to do that, they
all need to know the metadata, which fields are available and what are their types. Centralizing the schema management
enables schema versioning (consumers transparently gets old schemas to decode old messages) and data policy
enforcement (schemas can evolve safely without introducing breaking changes). The data storage and processing is more
efficient because yuu don't need to send the schema with each message (sometime it greater than the payload), you don't
need to store the field names, and numbers can be stored in their more efficient binary representation.

![](images/serdes.png)

[Red Hat Service Registry](https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-service-registry)
is based on [Apicurio Registry](https://www.apicur.io/registry), which is a schema registry for REST APIs (OpenAPI) and
message schemas (AsyncAPI). It supports pluggable storage (in-memory, Kafka, PostgreSQL), schema versioning, validation
and provides Java serializers/deserializers (SerDes) for Avro, Protobuf and JSON Schema. Kafka clients can use a Maven
plugin to automatically register the artifacts at build time. In addition to the registry core REST API, that can be
used to query the registry and create/update artifacts, we also have a translation layer for Confluent registry API (the
upstream `exportConfluent` tool helps with schemas migration).

A registered schema is uniquely identified by the tuple `(groupId, artifactId, version)`. The `groupId` is provided by
the user and it is just a way to logically group artifacts. By default, the `artifactId` is equal to the topic name plus
`-key` or `-value` suffix, depending on whether the serializer was used for the message key or value. The `globalId`
and `contentId` are generated by the server. The `globalId` is the unique id of an artifact version, while
the `contentId` is the unique id of the artifact content (different artifacts with the same schema have the same id).

The serializer exchanges the `artifactId` for a server generated `globalId`, which is added as record header or payload,
depending on the configuration of the producer application. The deserializer fetches the right schema version
by `globalId`. If required, you can configure to fetch by `contentId` (Confluent default). The `CHECK_PERIOD_MS` is the
time after which a cached artifact is auto evicted and needs to be fetched again on the next record (default: 30s).

### Using the schema registry

We are going to deploy a Service Registry instance on OpenShift along with a Kafka cluster, register a simple Avro
schema using the Maven plugin and try to send and receive some messages using the Kafka APIs.

[Deploy the Streams operator and Kafka cluster](/sessions/001). Then, we need to install the Service Registry operator
and wait some time for the pod to come up.

```
$ kubectl create -f sessions/003/sub.yaml
subscription.operators.coreos.com/my-svcreg created
Error from server (AlreadyExists): error when creating "sessions/003/sub.yaml": operatorgroups.operators.coreos.com "local-operators" already exists

$ kubectl get po -n openshift-operators
NAME                                                     READY   STATUS    RESTARTS   AGE
amq-streams-cluster-operator-v2.1.0-8-6dfcc6449d-c2np5   1/1     Running   3          2d20h
apicurio-registry-operator-fb9ffd5cb-89z89               1/1     Running   0          46s
```

Once the Kafka cluster is up and running, we can deploy PostgreSQL and the Service Registry. The registry also provides
a convenient web console that you can access using the URL in the CR status.

```
$ kubectl create -f sessions/003/crs
configmap/my-pgsql-init created
persistentvolumeclaim/my-pgsql-pvc created
configmap/my-pgsql-config created
configmap/my-pgsql-env created
statefulset.apps/my-pgsql-ss created
service/my-pgsql-svc created
apicurioregistry.registry.apicur.io/my-registry created

$ kubectl get po
NAME                                              READY   STATUS    RESTARTS   AGE
pod/my-cluster-entity-operator-6b68959588-698hp   3/3     Running   0          165m
pod/my-cluster-kafka-0                            1/1     Running   0          166m
pod/my-cluster-kafka-1                            1/1     Running   0          166m
pod/my-cluster-kafka-2                            1/1     Running   0          166m
pod/my-cluster-zookeeper-0                        1/1     Running   0          168m
pod/my-cluster-zookeeper-1                        1/1     Running   0          168m
pod/my-cluster-zookeeper-2                        1/1     Running   0          168m
pod/my-pgsql-ss-0                                 1/1     Running   0          8m36s
pod/my-registry-deployment-5f5fb7c786-7tj75       1/1     Running   0          53s
```

When all pods are running, we just need to tell our application where it can find the Kafka cluster, the registry and
provide truststore location and password.

```
$ export BOOTSTRAP_SERVERS=$(kubectl get k my-cluster -o yaml | yq e '.status.listeners[2].bootstrapServers') \
  && export REGISTRY_URL="http://$(kubectl get apicurioregistries my-registry -o 'jsonpath={.status.info.host}')/apis/registry/v2" \
  && kubectl get secret my-cluster-cluster-ca-cert -o "jsonpath={.data['ca\.p12']}" | base64 -d > /tmp/truststore.p12 \
  && export SSL_TRUSTSTORE_LOCATION="/tmp/truststore.p12" \
  && export SSL_TRUSTSTORE_PASSWORD=$(kubectl get secret my-cluster-cluster-ca-cert -o "jsonpath={.data['ca\.password']}" | base64 -d)

$ pushd sessions/003/kafka-avro && mvn clean compile exec:java -q && popd
~/Documents/streams-debugging/sessions/003/kafka-avro ~/Documents/streams-debugging
Producing records
Records produced
Consuming all records
Record: Hello-1663594981476
Record: Hello-1663594982041
Record: Hello-1663594982041
Record: Hello-1663594982041
Record: Hello-1663594982042
~/Documents/streams-debugging
```

[Look at the code](kafka-avro) to see how the schema is registered and used. Registration happens at build time and the
Maven plugin execute the following API request for every configured schema artifact. Note that we are using the default
group id, but you can specify a custom one.

```
$ export REGISTRY_URL="http://$(kubectl get apicurioregistries my-registry -o 'jsonpath={.status.info.host}')/apis/registry/v2"
$ curl -s -X POST -H "Content-Type: application/json" \
  -H "X-Registry-ArtifactId: my-topic-value" -H "X-Registry-ArtifactType: AVRO" \
    -d @src/main/resources/greeting.avsc $REGISTRY_URL/groups/default/artifacts?ifExists=RETURN_OR_UPDATE
{
  "name": "Greeting",
  "createdBy": "",
  "createdOn": "2022-09-30T06:31:36+0000",
  "modifiedBy": "",
  "modifiedOn": "2022-09-30T06:31:36+0000",
  "id": "my-topic-value",
  "version": "1",
  "type": "AVRO",
  "globalId": 4,
  "state": "ENABLED",
  "contentId": 6
}
```

Ok, now let's use the API to confirm that our schema was registered correctly. I can also look at the content and
metadata, which may be useful for troubleshooting.

```
$ curl -s $REGISTRY_URL/search/artifacts | jq
{
  "artifacts": [
    {
      "id": "my-topic-value",
      "name": "Greeting",
      "createdOn": "2022-09-19T13:42:59+0000",
      "createdBy": "",
      "type": "AVRO",
      "state": "ENABLED",
      "modifiedOn": "2022-09-19T13:42:59+0000",
      "modifiedBy": ""
    }
  ],
  "count": 1
}

$ curl -s $REGISTRY_URL/groups/default/artifacts/my-topic-value | jq
{
  "type": "record",
  "name": "Greeting",
  "fields": [
    {
      "name": "Message",
      "type": "string"
    },
    {
      "name": "Time",
      "type": "long"
    }
  ]
}

$ curl -s $REGISTRY_URL/groups/default/artifacts/my-topic-value/meta | jq
{
  "name": "Greeting",
  "createdBy": "",
  "createdOn": "2022-09-19T13:42:59+0000",
  "modifiedBy": "",
  "modifiedOn": "2022-09-19T13:42:59+0000",
  "id": "my-topic-value",
  "version": "1",
  "type": "AVRO",
  "globalId": 1,
  "state": "ENABLED",
  "contentId": 1
}
```
